{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import sklearn.preprocessing\n",
    "import sklearn.cross_validation\n",
    "import sklearn.externals\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2871: DtypeWarning: Columns (8,9,10,11,12,43,157,196,214,225,228,229,231,235,238) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2871: DtypeWarning: Columns (8,9,10,11,12,43,157,167,177,196,214,225,228,229,231,235,238) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv').set_index(\"ID\")\n",
    "test = pd.read_csv('./test.csv').set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [c for c in train.columns if len(np.unique(train[c])) == 1]#Should later drop columns from train and test\n",
    "#print drop_cols\n",
    "train.drop(drop_cols, axis = 1, inplace = True)\n",
    "test.drop(drop_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_cols = train.columns[train.dtypes == 'object']\n",
    "dates_cols =['VAR_0073', 'VAR_0075', 'VAR_0156', 'VAR_0157', 'VAR_0158', 'VAR_0159', 'VAR_0166', 'VAR_0167', 'VAR_0168', 'VAR_0169', 'VAR_0176', 'VAR_0177', 'VAR_0178','VAR_0179', 'VAR_0204', 'VAR_0217']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant_0008 = ['VAR_0008', 'VAR_0009', 'VAR_0010','VAR_0011','VAR_0012', 'VAR_0043','VAR_0044','VAR_0196', 'VAR_0229', ] #Contains redundant information\n",
    "train.drop(redundant_0008, axis = 1, inplace = True)\n",
    "test.drop(redundant_0008, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['NaN'] = 0\n",
    "test['NaN'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in test.columns: #Engineered Feature #1\n",
    "    train['NaN'] += pd.isnull(train[c])\n",
    "    test['NaN'] += pd.isnull(test[c])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_date(date_str):\n",
    "    if pd.notnull(date_str):\n",
    "        return datetime.datetime.strptime(date_str, '%d%b%y:%H:%M:%S')\n",
    "    else:\n",
    "        return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in dates_cols:\n",
    "    train[c] = train[c].apply(to_date)\n",
    "    test[c] = test[c].apply(to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = list(set(test.columns[test.dtypes == 'datetime64[ns]']) - set(train.columns[train.dtypes == 'datetime64[ns]'])) ##test got converted into date time format while train is still object format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(diff, axis = 1, inplace = True)\n",
    "test.drop(diff, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_cols_fixed = train.columns[train.dtypes == 'datetime64[ns]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'VAR_0073', u'VAR_0075', u'VAR_0204', u'VAR_0217'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dates_cols_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['VAR_0204-VAR_0217'] = (train['VAR_0204'] - train['VAR_0217']).apply(lambda x: x.astype('timedelta64[D]')/np.timedelta64(1, 'D'))\n",
    "test['VAR_0204-VAR_0217'] = (test['VAR_0204'] - test['VAR_0217']).apply(lambda x: x.astype('timedelta64[D]')/np.timedelta64(1, 'D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['VAR_0204-VAR_0075'] = (train['VAR_0204'] - train['VAR_0075']).apply(lambda x: x.astype('timedelta64[D]')/np.timedelta64(1, 'D'))\n",
    "test['VAR_0204-VAR_0075'] = (test['VAR_0204'] - test['VAR_0075']).apply(lambda x: x.astype('timedelta64[D]')/np.timedelta64(1, 'D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['VAR_0073_ISNULL'] = pd.isnull(train['VAR_0073']).astype('int')\n",
    "test['VAR_0073_ISNULL'] = pd.isnull(test['VAR_0073']).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors_dates = [] #Does not matter because will convert to float\n",
    "for c in dates_cols_fixed: \n",
    "    try:\n",
    "        train[c+'_YEAR'] = train[c].apply(lambda x: x.year)\n",
    "        test[c+'_YEAR'] = test[c].apply(lambda x: x.year)\n",
    "        train[c+'_MONTH'] = train[c].apply(lambda x: x.month)\n",
    "        test[c+'_MONTH'] = test[c].apply(lambda x: x.month)\n",
    "    except:\n",
    "        errors_dates.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(dates_cols_fixed, axis = 1, inplace=True)\n",
    "test.drop(dates_cols_fixed, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_cols = train.columns[train.dtypes == 'object']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random.seed(1)\n",
    "#m,n = train.shape\n",
    "#r = np.random.choice(m, size = 20000, replace=False)\n",
    "#for c in object_cols:\n",
    "#    print c, Counter(train.loc[r,c]).most_common(20)\n",
    "#    print '\\n\\n'\n",
    "\n",
    "#Unfixed dates ['VAR_0157','VAR_0167','VAR_0177']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unfixed_dates = ['VAR_0157','VAR_0167','VAR_0177']   \n",
    "train.drop(unfixed_dates, axis=1, inplace = True)\n",
    "test.drop(unfixed_dates, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_cols = train.columns[train.dtypes == 'object']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train[object_cols].fillna(-1, inplace = True)\n",
    "#test[object_cols].fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:,object_cols] = train[object_cols].fillna(-1)\n",
    "test.loc[:,object_cols] = test[object_cols].fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_cols = train.columns[train.dtypes == 'object']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "errors = []\n",
    "for col in object_cols:\n",
    "    if col not in dates_cols:\n",
    "        encoders[col] = LabelEncoder()\n",
    "        encoders[col].fit(pd.concat((train[col], test[col])))\n",
    "        try:\n",
    "            train[col] = encoders[col].transform(train[col])\n",
    "            test[col] = encoders[col].transform(test[col])\n",
    "        except:\n",
    "            errors.append(col)\n",
    "            #del train[col]\n",
    "            #del test[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'VAR_0158'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "object_cols = train.columns[train.dtypes == 'object']\n",
    "#print object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(object_cols, axis=1, inplace = True)\n",
    "test.drop(object_cols, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print train.info()\n",
    "#print test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop('target', axis = 1).values\n",
    "y = train.target.values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = sklearn.preprocessing.Imputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_clf2 = xgb.XGBClassifier(max_depth=8, learning_rate=.006, n_estimators=1500, subsample=.8, \\\n",
    "                            colsample_bytree=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cvs = sklearn.cross_validation.cross_val_score(xgb_clf2, X, y, scoring = 'roc_auc', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78679982,  0.78915165,  0.78801151,  0.79002286,  0.78742216])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_clf2.fit(X, y)\n",
    "y_pred = xgb_clf2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37301168,  0.37541601,  0.33667192, ...,  0.09639905,\n",
       "        0.2442822 ,  0.06244619], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAKING SUBMISSION\n",
    "#xgb_clf2.save_model('0001.model')\n",
    "#xgb_clf2.dump_model('dump.raw.txt', 'featmap.txt')\n",
    "\n",
    "submission = pd.DataFrame(y_pred[:,1], index=test.index, columns=['target'])\n",
    "submission.index.name = 'ID'\n",
    "submission.to_csv('B_XGB_006_1500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/XGB2_encoders.pkl',\n",
       " './models/XGB2_encoders.pkl_01.npy',\n",
       " './models/XGB2_encoders.pkl_02.npy',\n",
       " './models/XGB2_encoders.pkl_03.npy',\n",
       " './models/XGB2_encoders.pkl_04.npy',\n",
       " './models/XGB2_encoders.pkl_05.npy',\n",
       " './models/XGB2_encoders.pkl_06.npy',\n",
       " './models/XGB2_encoders.pkl_07.npy',\n",
       " './models/XGB2_encoders.pkl_08.npy',\n",
       " './models/XGB2_encoders.pkl_09.npy',\n",
       " './models/XGB2_encoders.pkl_10.npy',\n",
       " './models/XGB2_encoders.pkl_11.npy',\n",
       " './models/XGB2_encoders.pkl_12.npy',\n",
       " './models/XGB2_encoders.pkl_13.npy',\n",
       " './models/XGB2_encoders.pkl_14.npy',\n",
       " './models/XGB2_encoders.pkl_15.npy',\n",
       " './models/XGB2_encoders.pkl_16.npy',\n",
       " './models/XGB2_encoders.pkl_17.npy',\n",
       " './models/XGB2_encoders.pkl_18.npy']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.externals.joblib.dump(xgb_clf2, './models/XGB2.pkl')\n",
    "sklearn.externals.joblib.dump(encoders, './models/XGB2_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb2_load = sklearn.externals.joblib.load('./models/XGB2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid_params = {'max_depth':[6, 10, 12],'learning_rate':[.008, .012], \\\n",
    "#               'n_estimators':[1500, 2500], 'subsample':[.7, .9], 'colsample_bytree':[.6, .8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_params = {'max_depth':[6, 10, 14],'learning_rate':[.010, .015], \\\n",
    "               'n_estimators':[1500, 2500], 'subsample':[.7, .9], 'colsample_bytree':[.6, .8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_gridsearch = RandomizedSearchCV(bst, param_distributions = grid_params, \\\n",
    "                                     n_iter = 20, scoring = 'roc_auc', cv = 4, verbose = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_gridsearch.fit(X,y) #Not sure if this works?\n",
    "best_xgb = rand_gridsearch.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.6, 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "print rand_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.74438, std: 0.00100, params: {'n_estimators': 15, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.6, 'max_depth': 6}\n",
      "mean: 0.74021, std: 0.00094, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.75399, std: 0.00013, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.008, 'colsample_bytree': 0.6, 'max_depth': 12}\n",
      "mean: 0.75936, std: 0.00088, params: {'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.6, 'max_depth': 12}\n",
      "mean: 0.75661, std: 0.00063, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 10}\n",
      "mean: 0.74169, std: 0.00067, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.74676, std: 0.00096, params: {'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.75399, std: 0.00013, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.008, 'colsample_bytree': 0.6, 'max_depth': 12}\n",
      "mean: 0.75756, std: 0.00019, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 12}\n",
      "mean: 0.75936, std: 0.00088, params: {'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.6, 'max_depth': 12}\n",
      "mean: 0.74350, std: 0.00139, params: {'n_estimators': 15, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.74350, std: 0.00131, params: {'n_estimators': 15, 'subsample': 0.7, 'learning_rate': 0.008, 'colsample_bytree': 0.6, 'max_depth': 6}\n",
      "mean: 0.74515, std: 0.00046, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.74676, std: 0.00096, params: {'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.75839, std: 0.00034, params: {'n_estimators': 25, 'subsample': 0.7, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 12}\n",
      "mean: 0.75162, std: 0.00115, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'max_depth': 12}\n",
      "mean: 0.75883, std: 0.00051, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.6, 'max_depth': 10}\n",
      "mean: 0.75661, std: 0.00063, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 10}\n",
      "mean: 0.74169, std: 0.00067, params: {'n_estimators': 15, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "mean: 0.75661, std: 0.00063, params: {'n_estimators': 25, 'subsample': 0.9, 'learning_rate': 0.012, 'colsample_bytree': 0.8, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "for s in rand_gridsearch.grid_scores_:\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = rand_gridsearch.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rand_gridsearch.predict_proba(X_test)\n",
    "\n",
    "#MAKING SUBMISSION\n",
    "#xgb_clf2.save_model('0001_grid.model')\n",
    "#xgb_clf2.dump_model('dump_grid.raw.txt', 'featmap_grid.txt')\n",
    "\n",
    "submission = pd.DataFrame(y_pred, index=test.index, columns=['target'])\n",
    "submission.index.name = 'ID'\n",
    "submission.to_csv('B_XGB_GridSearch.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

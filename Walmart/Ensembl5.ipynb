{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import theano\n",
    "from lasagne import layers, nonlinearities\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submission_name = sys.argv[0].split('.')[0]\n",
    "#print 'Generating Submission: ' + submission_name\n",
    "\n",
    "train = pd.read_csv('./train.csv') #Last visit number is 191347\n",
    "test = pd.read_csv('./test.csv') #Last visit number is 191348\n",
    "\n",
    "full_df = pd.concat((train, test))\n",
    "\n",
    "full_df_negatives = full_df[full_df.ScanCount < 0]\n",
    "full_df_negatives_agg = full_df_negatives.groupby(['VisitNumber']).agg({'ScanCount':np.sum}) #Negative Feature Count\n",
    "\n",
    "full_df_uncategorized = full_df[pd.isnull(full_df.Upc)]\n",
    "full_df_uncategorized_agg = full_df_uncategorized.groupby(['VisitNumber']).agg({'ScanCount':np.sum}) #Unknown Feature Count\n",
    "\n",
    "full_df_totals = full_df[full_df.ScanCount > 0]\n",
    "full_df_totals_agg = full_df_totals.groupby(['VisitNumber']).agg({'ScanCount':np.sum}) #Total purchases Feature Count\n",
    "\n",
    "\n",
    "full_df.Upc.fillna(-100, inplace=True)\n",
    "full_df.DepartmentDescription.fillna('UNKNOWN', inplace=True)\n",
    "full_df.FinelineNumber.fillna(-100, inplace=True)\n",
    "\n",
    "visit_days = full_df.loc[:,['VisitNumber','Weekday']]\n",
    "visit_days.drop_duplicates('VisitNumber', inplace = True)\n",
    "visit_days.set_index('VisitNumber', inplace = True)\n",
    "visit_days = pd.get_dummies(visit_days) #Generating an interaction term with visit days would be useful\n",
    "\n",
    "full_df['FinelineNumber'] = full_df['FinelineNumber'].astype('int')\n",
    "full_df['DeptItems'] = full_df.DepartmentDescription +' ' + full_df.FinelineNumber.astype('str')\n",
    "\n",
    "\n",
    "full_df.loc[full_df.ScanCount < 0, 'DeptItems'] = '-' + full_df.loc[full_df.ScanCount < 0, :].DeptItems\n",
    "full_df['ScanCount'] = np.abs(full_df.ScanCount)\n",
    "full_df['ScanCount'] = full_df.ScanCount.astype('float32')\n",
    "\n",
    "full_deptitems_df = pd.pivot_table(full_df[full_df.ScanCount>0], values='ScanCount', index='VisitNumber',columns='DeptItems', aggfunc=np.sum)\n",
    "full_deptitems_df.fillna(0, inplace=True)\n",
    "\n",
    "y_df = full_df.loc[:, ['VisitNumber', 'TripType']]\n",
    "y_df.drop_duplicates('VisitNumber', inplace=True)\n",
    "y_df.set_index('VisitNumber', inplace=True)\n",
    "\n",
    "y_df = y_df.join(full_deptitems_df) #This requires an insane amount of memory **Cannot fill 0s due to memory error\n",
    "\n",
    "del full_deptitems_df\n",
    "\n",
    "X_train = y_df[pd.notnull(y_df.TripType)].drop('TripType', axis = 1).values\n",
    "X_test = y_df[pd.isnull(y_df.TripType)].drop('TripType', axis = 1).values\n",
    "y_train = y_df[pd.notnull(y_df.TripType)]['TripType'].values\n",
    "\n",
    "\n",
    "y_df = y_df[['TripType']] #Removing Unneccessary Columns\n",
    "\n",
    "X_train = np.nan_to_num(X_train) #Splitting this into 2 cells works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visit_days_interaction = visit_days.join(full_df_totals_agg)\n",
    "visit_days_interaction.fillna(value = 0, inplace = True)\n",
    "for c in visit_days_interaction:\n",
    "    if 'Weekday' in c:\n",
    "        visit_days_interaction[c] = visit_days_interaction[c] * visit_days_interaction.ScanCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.pivot_table(full_df, values='ScanCount', index='VisitNumber',columns='DepartmentDescription', aggfunc=np.sum)\n",
    "X_df.fillna(0, inplace=True)\n",
    "\n",
    "X_df = X_df.join(full_df_totals_agg, rsuffix='Totals')\n",
    "X_df = X_df.join(full_df_uncategorized_agg, rsuffix='Uncategorized')\n",
    "X_df = X_df.join(full_df_negatives_agg, rsuffix='Negatives')\n",
    "X_df = X_df.join(visit_days)\n",
    "X_df = X_df.join(visit_days_interaction,rsuffix='interaction')\n",
    "X_df.fillna(0, inplace = True)\n",
    "\n",
    "y_df = y_df.join(X_df)\n",
    "\n",
    "X_train2 = y_df[pd.notnull(y_df.TripType)].drop('TripType', axis = 1).values\n",
    "X_test2 = y_df[pd.isnull(y_df.TripType)].drop('TripType', axis = 1).values\n",
    "y_train2 = y_df[pd.notnull(y_df.TripType)]['TripType'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros_index_train = np.sum(X_train, axis = 0) == 0 #2389 zeros in array\n",
    "zeros_index_test = np.sum(X_test, axis = 0) == 0 #2310 zeros in array\n",
    "zeros_index = zeros_index_train | zeros_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:,~zeros_index]\n",
    "X_test = X_test[:,~zeros_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi_sq_best = SelectKBest(score_func=chi2, k = 11000)\n",
    "chi_sq_best.fit(X_train,y_train)\n",
    "\n",
    "X_train = chi_sq_best.transform(X_train)\n",
    "\n",
    "X_test = np.nan_to_num(X_test)\n",
    "X_test = chi_sq_best.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_train2), axis = 1)\n",
    "X_test = np.concatenate((X_test, X_test2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 2620326 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input      10087\n",
      "  1  dropout    10087\n",
      "  2  hidden1      256\n",
      "  3  dropout1     256\n",
      "  4  hidden2      128\n",
      "  5  dropout2     128\n",
      "  6  output        38\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m3.31065\u001b[0m       \u001b[32m3.08407\u001b[0m      1.07347      0.24755  2.91s\n",
      "      2       \u001b[36m2.96822\u001b[0m       \u001b[32m2.73843\u001b[0m      1.08391      0.32792  3.04s\n",
      "      3       \u001b[36m2.62543\u001b[0m       \u001b[32m2.38289\u001b[0m      1.10178      0.35687  3.07s\n",
      "      4       \u001b[36m2.34332\u001b[0m       \u001b[32m2.11989\u001b[0m      1.10540      0.41344  3.20s\n",
      "      5       \u001b[36m2.14714\u001b[0m       \u001b[32m1.92895\u001b[0m      1.11312      0.50193  2.96s\n",
      "      6       \u001b[36m2.00749\u001b[0m       \u001b[32m1.78820\u001b[0m      1.12263      0.54396  2.91s\n",
      "      7       \u001b[36m1.90642\u001b[0m       \u001b[32m1.74748\u001b[0m      1.09095      0.52911  2.86s\n",
      "      8       \u001b[36m1.83637\u001b[0m       \u001b[32m1.63440\u001b[0m      1.12358      0.58505  2.86s\n",
      "      9       \u001b[36m1.75479\u001b[0m       \u001b[32m1.55306\u001b[0m      1.12989      0.58849  2.84s\n",
      "     10       \u001b[36m1.69155\u001b[0m       \u001b[32m1.48172\u001b[0m      1.14161      0.61313  2.85s\n",
      "     11       \u001b[36m1.63696\u001b[0m       \u001b[32m1.43325\u001b[0m      1.14213      0.61380  2.84s\n",
      "     12       \u001b[36m1.59608\u001b[0m       \u001b[32m1.39198\u001b[0m      1.14663      0.62313  2.82s\n",
      "     13       \u001b[36m1.56022\u001b[0m       \u001b[32m1.35699\u001b[0m      1.14977      0.63021  2.91s\n",
      "     14       \u001b[36m1.52293\u001b[0m       \u001b[32m1.32254\u001b[0m      1.15152      0.63618  2.91s\n",
      "     15       \u001b[36m1.50065\u001b[0m       \u001b[32m1.29609\u001b[0m      1.15783      0.63665  2.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:412: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f403d55a810>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f40295b7610>,\n",
       "     custom_score=None, dropout1_p=0.2, dropout2_p=0.2, dropout_p=0.1,\n",
       "     hidden1_num_units=256, hidden2_num_units=128,\n",
       "     input_shape=(None, 10087),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('hidden1', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout1', <class 'lasagne.layers.noise.DropoutLayer'>), ('hidden2', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout2', <class 'lasagne.layers.noise.DropoutLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=15, more_params={},\n",
       "     objective=<function objective at 0x7f403d5547d0>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f403d5ae410>,\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7f40295fe890>, <__main__.AdjustVariable object at 0x7f40295fe850>, <__main__.EarlyStopping object at 0x7f40295fe710>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f403d9eeb00>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f403d9eec68>],\n",
       "     output_nonlinearity=<function softmax at 0x7f403d9fa320>,\n",
       "     output_num_units=38, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f403d55a850>,\n",
       "     update=<function nesterov_momentum at 0x7f403d5aeb90>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=True,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(y_train)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_train = y_train.astype('int32')\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "        \n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()\n",
    "            \n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "nn = NeuralNet(layers = [\n",
    "     ('input', layers.InputLayer),\n",
    "     ('dropout', layers.DropoutLayer),\n",
    "     ('hidden1', layers.DenseLayer),\n",
    "     ('dropout1', layers.DropoutLayer),   \n",
    "     ('hidden2', layers.DenseLayer),\n",
    "     ('dropout2', layers.DropoutLayer),   \n",
    "     ('output', layers.DenseLayer),],\n",
    "               \n",
    "     input_shape = (None, X_train.shape[1]),\n",
    "     dropout_p =.10,\n",
    "               \n",
    "     hidden1_num_units = 256,\n",
    "     dropout1_p = .20,\n",
    "     hidden2_num_units = 128,\n",
    "     dropout2_p = .20,\n",
    "               \n",
    "     output_num_units = np.unique(y_train).shape[0],\n",
    "     output_nonlinearity = nonlinearities.softmax,\n",
    "               \n",
    "     update_learning_rate=theano.shared(float32(0.01)),\n",
    "     update_momentum=theano.shared(float32(0.9)),\n",
    "    \n",
    "     batch_iterator_train=BatchIterator(batch_size=2048),\n",
    "               \n",
    "     on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.01, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        EarlyStopping(patience=35)\n",
    "        ],\n",
    "\n",
    "     regression = False,\n",
    "     max_epochs = 500,\n",
    "     verbose = True\n",
    "      )\n",
    "\n",
    "nn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_, X_val, y_, y_val = train_test_split(X_train, y_train, test_size = 25000, random_state = 13)\n",
    "\n",
    "del X_\n",
    "del y_\n",
    "\n",
    "xgb = xgboost.XGBClassifier(max_depth = 14, n_estimators = 500,\n",
    "                        objective='multi:softprob', subsample = .80, colsample_bytree=.5)\n",
    "\n",
    "xgb.fit(X_train, y_train, eval_set = [(X_val, y_val)], eval_metric = 'mlogloss', early_stopping_rounds=35)\n",
    "\n",
    "y_xgb_train_predictions = xgb.predict_proba(X_train)\n",
    "y_nn_train_predictions = nn.predict_proba(X_train)\n",
    "\n",
    "X_ensembl_train = np.concatenate((y_xgb_train_predictions, y_nn_train_predictions), axis = 1)\n",
    "\n",
    "y_nn_test_predictions = nn.predict_proba(X_test)\n",
    "y_xgb_test_predictions = xgb.predict_proba(X_test)\n",
    "\n",
    "\n",
    "col_names = ['TripType_' + str(c) for c in enc.classes_.astype('int')]\n",
    "\n",
    "submission = pd.DataFrame(np.round(y_nn_test_predictions, 4), index=y_df[pd.isnull(y_df.TripType)].index, columns = col_names)\n",
    "submission.reset_index(inplace = True)\n",
    "submission.to_csv(submission_name + '_NN_10000Features.csv', index=False)\n",
    "\n",
    "submission = pd.DataFrame(np.round(y_xgb_test_predictions, 4), index=y_df[pd.isnull(y_df.TripType)].index, columns = col_names)\n",
    "submission.reset_index(inplace = True)\n",
    "submission.to_csv(submission_name + '_XGB_10000Features.csv', index=False)\n",
    "\n",
    "log_ensembl = LogisticRegression()\n",
    "log_ensembl.fit(X_ensembl_train, y_train)\n",
    "X_ensembl_test = np.concatenate((y_xgb_test_predictions, y_nn_test_predictions), axis = 1)\n",
    "\n",
    "y_probas = log_ensembl.predict_proba(X_ensembl_test)\n",
    "\n",
    "submission = pd.DataFrame(np.round(y_probas, 4), index=y_df[pd.isnull(y_df.TripType)].index, columns = col_names)\n",
    "submission.reset_index(inplace = True)\n",
    "submission.to_csv(submission_name + '_log_ensembl_10000Features-Notebook.csv', index=False)\n",
    "\n",
    "y_probas_avg = (y_xgb_test_predictions + y_nn_test_predictions)/2\n",
    "\n",
    "submission = pd.DataFrame(np.round(y_probas_avg,4), index=y_df[pd.isnull(y_df.TripType)].index, columns = col_names)\n",
    "submission.reset_index(inplace = True)\n",
    "submission.to_csv(submission_name + '_avg_ensembl_10000Features-Notebook.csv', index=False)\n",
    "\n",
    "joblib.dump(nn, './model/' + submission_name + '.nn')\n",
    "joblib.dump(xgb, './model/'+ submission_name + '.xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
